{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représenation de la labyrinthe\n",
    "# -------\n",
    "# |0|¤|1|\n",
    "# |2|3|4|\n",
    "# |5|¤|6|\n",
    "# -------\n",
    "\n",
    "# état initial = 0\n",
    "# état final = 6\n",
    "# ¤ est un obstacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from random import random\n",
    "alpha = 0.3\n",
    "gamma = 0.5\n",
    "iter_max = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=np.zeros((7,4))\n",
    "#matrice des récompenses\n",
    "R=np.array([(0,2,0,0),\n",
    "            (0,2,0,0),\n",
    "            (-2,-2,0,2),\n",
    "            (0,0,-3,3),\n",
    "            (-3,4,0,0),\n",
    "            (2,0,0,0),(0,0,0,0)])\n",
    "#matrice des actions possibles (les valeurs représentent les etats apres transition, 0 si action non possible)\n",
    "# H B G D\n",
    "m = np.array([(0, 3, 0, 0), \n",
    "              (0, 5, 0, 0), \n",
    "              (1, 6, 0, 4),\n",
    "              (0, 0, 3, 5), \n",
    "              (2, 7, 4, 0), \n",
    "              (3, 0, 0, 0),(0,0,0,0)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proba_gibbs(Q,s,a,m):\n",
    "    if m[s,a]==0:\n",
    "        return (0)\n",
    "    else:\n",
    "        sum = 0\n",
    "        for i in range(Q.shape[1]):\n",
    "            if m[s,i]:\n",
    "                sum+=math.exp(Q[s,i])\n",
    "        p= math.exp(Q[s, a])/sum\n",
    "        return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(Q,alpha,gamma,s,s2,a,r):\n",
    "    Q[s,a]=(1-alpha)* Q[s,a] + alpha *(r + gamma* np.max(Q[s2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning(Q, R,m, alpha=0.3,gamma=0.5,iter_max=7):\n",
    "    iter = 0\n",
    "    #s=0 #i=0 = s-1\n",
    "    while(iter<iter_max):\n",
    "        iter+=1\n",
    "        s=0\n",
    "        while(s!=6):\n",
    "            prob_distribution=[] #liste des probabilité de Gibbs (si l'action n'est pas possible alors l[i]=0)\n",
    "            for a in range(4):\n",
    "                prob_distribution.append(proba_gibbs(Q,s,a,m))\n",
    "            # draw a random number and conclude the action (0(H),1(B),2(G) ou 3(D))\n",
    "            # It returns a 1 sized list of elements chosen from [0,1,2,3] with a probability p=prob_distribution for each index.\n",
    "            x = np.random.choice([0, 1, 2, 3], 1, p=prob_distribution)\n",
    "            a = x[0]\n",
    "            # i=s-1# s2= new state after being in state \"s\" and choosing action \"a\"\n",
    "            s2 = m[s,a]-1\n",
    "            r = R[s,a]\n",
    "            update_Q(Q, alpha, gamma, s, s2, a, r)\n",
    "            s=s2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old Q-table \n",
      " [[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "new Q-table \n",
      " [[ 0.          3.5822711   0.          0.        ]\n",
      " [ 0.          0.68010913  0.          0.        ]\n",
      " [-0.51       -0.93        0.          3.97076217]\n",
      " [ 0.          0.         -0.81        4.67733541]\n",
      " [-0.9         3.8870099   0.53406084  0.        ]\n",
      " [ 1.173       0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"old Q-table \\n\",Q)\n",
    "Q_learning(Q, R,m, alpha=0.3,gamma=0.5,iter_max=10)\n",
    "print(\"new Q-table \\n\",Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cca9558bc5ad879ec93cc030b157d75f18267527c60932cecaace349eef54dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
